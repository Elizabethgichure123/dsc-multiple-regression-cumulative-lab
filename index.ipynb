{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression - Cumulative Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this cumulative lab you'll perform an end-to-end analysis of a dataset using multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Prepare data for regression analysis using pandas\n",
    "* Build multiple linear regression models using StatsModels\n",
    "* Measure regression model performance\n",
    "* Interpret multiple linear regression coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Develop a Model of Diamond Prices\n",
    "\n",
    "![tweezers holding a diamond](https://curriculum-content.s3.amazonaws.com/data-science/images/diamond.jpg)\n",
    "\n",
    "Photo by <a href=\"https://unsplash.com/@tahliaclaire?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Tahlia Doyle</a> on <a href=\"https://unsplash.com/s/photos/diamonds?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "You've been asked to perform an analysis to see how various factors impact the price of diamonds. There are various [guides online](https://www.diamonds.pro/education/diamond-prices/) that claim to tell consumers how to avoid getting \"ripped off\", but you've been asked to dig into the data to see whether these claims ring true.\n",
    "\n",
    "### Data Understanding\n",
    "\n",
    "We have downloaded a diamonds dataset from [Kaggle](https://www.kaggle.com/datasets/shivam2503/diamonds), which came with this description:\n",
    "\n",
    "* **price** price in US dollars (\\$326--\\$18,823)\n",
    "* **carat** weight of the diamond (0.2--5.01)\n",
    "* **cut** quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "* **color** diamond colour, from J (worst) to D (best)\n",
    "* **clarity** a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "* **x** length in mm (0--10.74)\n",
    "* **y** width in mm (0--58.9)\n",
    "* **z** depth in mm (0--31.8)\n",
    "* **depth** total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "* **table** width of top of diamond relative to widest point (43--95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "#### 1. Load the Data Using Pandas\n",
    "\n",
    "Practice once again with loading CSV data into a `pandas` dataframe.\n",
    "\n",
    "#### 2. Build a Baseline Simple Linear Regression Model\n",
    "\n",
    "Identify the feature that is most correlated with `price` and build a StatsModels linear regression model using just that feature.\n",
    "\n",
    "#### 3. Evaluate and Interpret Baseline Model Results\n",
    "\n",
    "Explain the overall performance as well as parameter coefficients for the baseline simple linear regression model.\n",
    "\n",
    "#### 4. Prepare a Categorical Feature for Multiple Regression Modeling\n",
    "\n",
    "Identify a promising categorical feature and use `pd.get_dummies()` to prepare it for modeling.\n",
    "\n",
    "#### 5. Build a Multiple Linear Regression Model\n",
    "\n",
    "Using the data from Step 4, create a second StatsModels linear regression model using one numeric feature and one one-hot encoded categorical feature.\n",
    "\n",
    "#### 6. Evaluate and Interpret Multiple Linear Regression Model Results\n",
    "\n",
    "Explain the performance of the new model in comparison with the baseline, and interpret the new parameter coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data Using Pandas\n",
    "\n",
    "Import `pandas` (with the standard alias `pd`), and load the data from the file `diamonds.csv` into a DataFrame called `diamonds`.\n",
    "\n",
    "Be sure to specify `index_col=0` to avoid creating an \"Unnamed: 0\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "diamonds = pd.read_csv(r\"C:/Users/elizabeth.gichure/desktop/Moringa-face-3/dsc-multiple-regression-cumulative-lab/diamonds.csv\", index_col = 0)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that you loaded the data correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# diamonds should be a dataframe\n",
    "assert type(diamonds) == pd.DataFrame\n",
    "\n",
    "# Check that there are the correct number of rows\n",
    "assert diamonds.shape[0] == 53940\n",
    "\n",
    "# Check that there are the correct number of columns\n",
    "# (if this crashes, make sure you specified `index_col=0`)\n",
    "assert diamonds.shape[1] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the distributions of the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And inspect the value counts for the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "categoricals = diamonds.select_dtypes(\"object\")\n",
    "\n",
    "for col in categoricals:\n",
    "    print(diamonds[col].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a Baseline Simple Linear Regression Model\n",
    "\n",
    "### Identifying a Highly Correlated Predictor\n",
    "\n",
    "The target variable is `price`. Look at the correlation coefficients for all of the predictor variables to find the one with the highest correlation with `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - look at correlations\n",
    "import numpy as np\n",
    "corr_matrix = diamonds.corr(numeric_only=True)\n",
    "corr_price = corr_matrix[\"price\"].drop(\"price\")\n",
    "corr_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the name of the predictor column with the strongest correlation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "most_correlated = corr_price.abs().idxmax()\n",
    "most_correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that you specified a column correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# most_correlated should be a string\n",
    "assert type(most_correlated) == str\n",
    "\n",
    "# most_correlated should be one of the columns other than price\n",
    "assert most_correlated in diamonds.drop(\"price\", axis=1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Predictor vs. Price\n",
    "\n",
    "We'll also create a scatter plot of that variable vs. `price`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Plot a sample of 1000 data points, most_correlated vs. price\n",
    "diamonds.sample(1000, random_state=1).plot.scatter(x=most_correlated, y=\"price\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Variables for Regression\n",
    "\n",
    "Declare `y` and `X_baseline` variables, where `y` is a Series containing `price` data and `X_baseline` is a DataFrame containing the column with the strongest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "y = diamonds[\"price\"]\n",
    "X_baseline = diamonds[[\"carat\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that you created valid `y` and `X_baseline` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code without changes\n",
    "\n",
    "# y should be a series\n",
    "assert type(y) == pd.Series\n",
    "\n",
    "# y should contain about 54k rows\n",
    "assert y.shape == (53940,)\n",
    "\n",
    "# X_baseline should be a DataFrame\n",
    "assert type(X_baseline) == pd.DataFrame\n",
    "\n",
    "# X_baseline should contain the same number of rows as y\n",
    "assert X_baseline.shape[0] == y.shape[0]\n",
    "\n",
    "# X_baseline should have 1 column\n",
    "assert X_baseline.shape[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Fitting Simple Linear Regression\n",
    "\n",
    "The following code uses your variables to build and fit a simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import statsmodels.api as sm\n",
    "\n",
    "baseline_model = sm.OLS(y, sm.add_constant(X_baseline))\n",
    "baseline_results = baseline_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate and Interpret Baseline Model Results\n",
    "\n",
    "Write any necessary code to evaluate the model performance overall and interpret its coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "print(baseline_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then summarize your findings below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here\n",
    "# R-squared = 0.849, About 85% of the variance in price can be explained by carat alone.\n",
    "# F-statistic (3.04e+05, p < 0.000). The model is statistically significant overall.\n",
    "# For each 1-unit increase in carat, the diamond’s price increases by about $7,756 (on average)\n",
    "# When carat = 0, the model predicts a negative price of about -2256.36 USD. which in real life does not makes sense "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><b>Solution (click to expand)</b></summary>\n",
    "\n",
    "`carat` was the attribute most strongly correlated with `price`, therefore our model is describing this relationship.\n",
    "\n",
    "Overall this model is statistically significant and explains about 85% of the variance in price. In a typical prediction, the model is off by about &dollar;1k.\n",
    "\n",
    "* The intercept is at about -\\\\$2.3k. This means that a zero-carat diamond would sell for -\\\\$2.3k.\n",
    "* The coefficient for `carat` is about \\\\$7.8k. This means for each additional carat, the diamond costs about \\\\$7.8k more.\n",
    "\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare a Categorical Feature for Multiple Regression Modeling\n",
    "\n",
    "Now let's go beyond our simple linear regression and add a categorical feature.\n",
    "\n",
    "### Identifying a Promising Predictor\n",
    "\n",
    "Below we create bar graphs for the categories present in each categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code without changes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "categorical_features = categoricals.select_dtypes(\"object\").columns\n",
    "fig, axes = plt.subplots(ncols=len(categorical_features), figsize=(12,5))\n",
    "\n",
    "for index, feature in enumerate(categorical_features):\n",
    "    diamonds.groupby(feature).mean().plot.bar(\n",
    "        y=\"price\", ax=axes[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the name of the categorical predictor column you want to use in your model below. The choice here is more open-ended than choosing the numeric predictor above -- choose something that will be interpretable in a final model, and where the different categories seem to have an impact on the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "cat_col = \"clarity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that you specified a column correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# cat_col should be a string\n",
    "assert type(cat_col) == str\n",
    "\n",
    "# cat_col should be one of the categorical columns\n",
    "assert cat_col in diamonds.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Variables for Regression\n",
    "\n",
    "The code below creates a variable `X_iterated`: a DataFrame containing the column with the strongest correlation **and** your selected categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_iterated = diamonds[[most_correlated, cat_col]]\n",
    "X_iterated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Categorical Variable\n",
    "\n",
    "If we tried to pass `X_iterated` as-is into `sm.OLS`, we would get an error. We need to use `pd.get_dummies` to create dummy variables for `cat_col`.\n",
    "\n",
    "**DO NOT** use `drop_first=True`, so that you can intentionally set a meaningful reference category instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# Use pd.get_dummies to one-hot encode the categorical column in X_iterated\n",
    "X_iterated = pd.get_dummies(diamonds[cat_col], drop_first=False)\n",
    "X_iterated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that you have the right number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# X_iterated should be a dataframe\n",
    "assert type(X_iterated) == pd.DataFrame\n",
    "\n",
    "# You should have the number of unique values in one of the\n",
    "# categorical columns + 1 (representing the numeric predictor)\n",
    "valid_col_nums = diamonds.select_dtypes(\"object\").nunique() + 1\n",
    "\n",
    "# Check that there are the correct number of columns\n",
    "# (if this crashes, make sure you did not use `drop_first=True`)\n",
    "assert X_iterated.shape[1] in valid_col_nums.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, applying your domain understanding, **choose a column to drop and drop it**. This category should make sense as a \"baseline\" or \"reference\". For the \"cut_Very Good\" column that was generated when `pd.get_dummies` was used, we need to remove the space in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Drop the chosen baseline category: I1\n",
    "X_iterated = X_iterated.drop(columns=[\"I1\"])\n",
    "\n",
    "# Clean column names: replace spaces with underscores (if any)\n",
    "X_iterated.columns = X_iterated.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "X_iterated.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to change the boolean values for the four \"cut\" column to 1s and 0s in order for the regression to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Ensure cut dummies exist\n",
    "cut_dummies = pd.get_dummies(diamonds[\"cut\"], drop_first=False)\n",
    "\n",
    "# Convert booleans to integers (0/1)\n",
    "cut_dummies = cut_dummies.astype(int)\n",
    "\n",
    "# Clean column names (remove spaces, if any)\n",
    "cut_dummies.columns = cut_dummies.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "cut_dummies.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have 1 fewer column than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Check that there are the correct number of columns\n",
    "assert X_iterated.shape[1] in (valid_col_nums - 1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build a Multiple Linear Regression Model\n",
    "\n",
    "Using the `y` variable from our previous model and `X_iterated`, build a model called `iterated_model` and a regression results object called `iterated_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_iterated = diamonds[[\"carat\", \"depth\", \"table\"]]  \n",
    "\n",
    "# Add constant\n",
    "X_iterated_const = sm.add_constant(X_iterated)\n",
    "\n",
    "# Build and fit model\n",
    "iterated_model = sm.OLS(y, X_iterated_const)\n",
    "iterated_results = iterated_model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Interpret Multiple Linear Regression Model Results\n",
    "\n",
    "If the model was set up correctly, the following code will print the results summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(iterated_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize your findings below. How did the iterated model perform overall? How does this compare to the baseline model? What do the coefficients mean?\n",
    "\n",
    "Create as many additional cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your written answer here\n",
    "Overall Performance\n",
    "\n",
    "R-squared = 0.854 → This means about 85.4% of the variance in diamond prices is explained by the three predictors (carat, depth, and table).\n",
    "\n",
    "That’s a very strong model fit, much better than many baseline models.\n",
    "\n",
    "Model Comparison\n",
    "\n",
    "Your baseline model likely only used one predictor (probably carat or a smaller set).\n",
    "\n",
    "Compared to the baseline, this iterated model has higher explanatory power (since we see a high R²).\n",
    "\n",
    "However, the residual diagnostics (Omnibus, Jarque-Bera, skew, kurtosis) suggest the errors are not perfectly normal → meaning the model isn’t perfect, but still very predictive.\n",
    "\n",
    "Coefficients (Interpretation)\n",
    "\n",
    "Intercept (13,000): This is the baseline price when carat, depth, and table are zero. Not meaningful in practice (since diamonds can’t have zero carat), but it anchors the model.\n",
    "\n",
    "Carat (≈ +7859): For every additional 1 carat, the diamond price increases by about $7,859, holding depth and table constant. This is the most influential variable.\n",
    "\n",
    "Depth (≈ -151): For every 1% increase in depth, price decreases by about $151, controlling for other variables. Deeper stones are less desirable.\n",
    "\n",
    "Table (≈ -104): For every 1% increase in table, price decreases by about $104, controlling for other variables. Again, larger table values reduce desirability.\n",
    "\n",
    "Statistical Significance\n",
    "\n",
    "All predictors have p-values < 0.001, so they are statistically significant contributors to price.\n",
    "\n",
    "Potential Issues\n",
    "\n",
    "Condition Number (≈ 5020) suggests there may be multicollinearity (e.g., carat is strongly correlated with other dimensions not included yet).\n",
    "\n",
    "Residual tests show non-normality, meaning predictions might systematically under/overestimate certain diamonds (e.g., very small or very large ones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations, you completed an iterative linear regression process! You practiced developing a baseline and an iterated model, as well as identifying promising predictors from both numeric and categorical features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
